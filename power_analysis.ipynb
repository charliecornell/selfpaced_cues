{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ddd9bf0",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208d2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for analyses\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr, ttest_rel\n",
    "from scipy import spatial\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "from mycolorpy import colorlist as mcp\n",
    "cset=mcp.gen_color(cmap=\"inferno\",n=8)\n",
    "from statsmodels.stats.power import TTestIndPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8830bf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m --- HUMAN DATA DETAILS --- \n",
      "\u001b[0m\n",
      " * 66 subjects included in analyses\n",
      " * 523 cued trials out of 792 total trials are included\n",
      " * Cue time M = 42.8, SD = 18.7 seconds\n",
      " * Pre-cue recall M = 7.68, SD = 3.22 seconds\n",
      " * Totalled recall M = 8.48, SD = 4.34 seconds\n"
     ]
    }
   ],
   "source": [
    "# obtain human data details\n",
    "exp='data/pilotdata_opt/'\n",
    "data_id=1 #data_id indicates folder for functions_overrides.py to use\n",
    "ll = 16   #list length\n",
    "ntrials_persub = 12 #number of expeirmental trials\n",
    "recall_time = 90000 #ms\n",
    "\n",
    "# only included trials, following exclusion criteria (see Methods):\n",
    "recs_amts_data = np.loadtxt(exp+'/recs_amts.txt',delimiter=',') #initial recall amount by trial\n",
    "cue_times_data = np.loadtxt(exp+'/cue_times.txt',delimiter=',') #cue request time into the 90 seconds\n",
    "rmdr_idxs_data = np.loadtxt(exp+'/rmdr.txt',delimiter=',')      #index of cue in remaining word list\n",
    "post_amts_data = np.loadtxt(exp+'/post_rmdr_amt.txt',delimiter=',')   #post-cue recall amount by trial\n",
    "\n",
    "ntrials = len(recs_amts_data) #number of included trials\n",
    "ntrials_all = len(np.loadtxt(exp+'/pres_all.txt',delimiter=',').tolist()) #total collected trials\n",
    "nsubjects = int(ntrials_all/ntrials_persub) #number of subjects overall\n",
    "\n",
    "print(\"\\n\\033[1m --- HUMAN DATA DETAILS --- \\n\\033[0m\")\n",
    "print(\" *\",nsubjects,\"subjects included in analyses\")\n",
    "print(\" *\",ntrials,\"cued trials out of\",ntrials_all,\"total trials are included\")\n",
    "print(\" * Cue time M = %.1f, SD = %.1f seconds\"%(np.mean(cue_times_data)/1000,np.std(cue_times_data)/1000))\n",
    "print(\" * Pre-cue recall M = %.2f, SD = %.2f seconds\"%(np.mean(recs_amts_data),np.std(recs_amts_data)))\n",
    "print(\" * Totalled recall M = %.2f, SD = %.2f seconds\"%(np.mean(recs_amts_data)+np.mean(post_amts_data),\n",
    "                                                        np.std(recs_amts_data) + np.std(post_amts_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed3449",
   "metadata": {},
   "source": [
    "### <p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3fe27b",
   "metadata": {},
   "source": [
    "### Simulate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b101fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CMR code\n",
    "from probCMR_overrides import CMR2Reminder\n",
    "from functions_overrides import FunctionsReminder\n",
    "functions = FunctionsReminder()\n",
    "\n",
    "\n",
    "# simulate CMR   \n",
    "# CMR_sp: serial positions of items recalled during initial recall (if N=1: matches empirical data)\n",
    "# reminders: serial positions of remaining items (ordered by their wordpool index value)\n",
    "# recalls: serial positions of items recalled post-cue (only for last repetition of reminder session)\n",
    "# accs: recall gain for every repetition of reminder session\n",
    "# pcas: row for each item; columns 0&1 is temporal context, columns 2&3 is semantic context\n",
    "# pcas2: row for each item; columns 0&1 are combined temporal and semantic context (ie., encoding context)\n",
    "# net_cs: encoding context vector for every item (ordered by presentation list order in each trial)\n",
    "CMR_sp,reminders,recalls,accs,pcas,pcas2,net_cs = functions.model_probCMR(N=1,ll=ll,lag_examine=4,data_id=data_id)\n",
    "\n",
    "\n",
    "# correct for an indexing difference from data and CMR output by finding shown reminder index in CMR's output \n",
    "# (as data files are ordered by serial position whereas CMR is order by wordpool index of the shown words\n",
    "rmdr_idxs_CMR = []; indx = 0\n",
    "for r in rmdr_idxs_data: \n",
    "    r = int(r.item())                        # index in remaining word list in data, ordered by presentation list\n",
    "    #print(reminders[indx])                  # the serial positions remaining, ordered by wordpool index\n",
    "    rem_sorted = np.sort(reminders[indx])    # the serial positions remaining, ordered by pres index\n",
    "    this_reminder = int(rem_sorted[r])       # corresponding sp value\n",
    "    r = reminders[indx].index(this_reminder) # index of reminder in CMR's sorted list\n",
    "    rmdr_idxs_CMR.append(r)\n",
    "    indx+=1\n",
    "    \n",
    "\n",
    "# get CMR's average performance gain from cues\n",
    "post_amts_CMRA = []\n",
    "for i in range(len(accs)):\n",
    "    acc = [np.mean(x) for x in accs[i]]\n",
    "    post_amts_CMRA.append(acc[rmdr_idxs_CMR[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818c6b9",
   "metadata": {},
   "source": [
    "### <p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378da73",
   "metadata": {},
   "source": [
    "### Power Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d4dce",
   "metadata": {},
   "source": [
    "#### 1. before/after ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b6e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.760247668243426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6826: RuntimeWarning: invalid value encountered in _nct_cdf\n",
      "  return np.clip(_boost._nct_cdf(x, df, nc), 0, 1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6826: RuntimeWarning: overflow encountered in _nct_cdf\n",
      "  return np.clip(_boost._nct_cdf(x, df, nc), 0, 1)\n"
     ]
    }
   ],
   "source": [
    "x = recs_amts_data\n",
    "y = [recs_amts_data[i] + post_amts_data[i] for i in range(ntrials)]\n",
    "\n",
    "u1 = np.mean(x); n1 = len(x); s1 = np.std(x)\n",
    "u2 = np.mean(y); n2 = len(y); s2 = np.std(y)\n",
    "d = (u1 - u2) / (np.sqrt( ((n1-1) * s1**2 + (n2-1) * s2**2 ) / (n1+n2-2)))\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "sample_size = power_analysis.solve_power(effect_size = d, alpha = 0.05, power = 0.95, alternative = 'smaller')\n",
    "print(sample_size/12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec7176",
   "metadata": {},
   "source": [
    "#### 2. partial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f9e628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.457313996339735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6832: RuntimeWarning: invalid value encountered in _nct_sf\n",
      "  return np.clip(_boost._nct_sf(x, df, nc), 0, 1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6826: RuntimeWarning: invalid value encountered in _nct_cdf\n",
      "  return np.clip(_boost._nct_cdf(x, df, nc), 0, 1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6832: RuntimeWarning: overflow encountered in _nct_sf\n",
      "  return np.clip(_boost._nct_sf(x, df, nc), 0, 1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6826: RuntimeWarning: overflow encountered in _nct_cdf\n",
      "  return np.clip(_boost._nct_cdf(x, df, nc), 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# log transform\n",
    "nRemaining = [16-i for i in recs_amts_data]\n",
    "nRemaining_log = [math.log(x+0.00001) for x in nRemaining]\n",
    "post_amts_data_log = [math.log(x+0.00001) for x in post_amts_data]\n",
    "post_amts_CMRA_log = [math.log(x+0.00001) for x in post_amts_CMRA]\n",
    "\n",
    "x = post_amts_data_log\n",
    "y = post_amts_CMRA_log\n",
    "covar = nRemaining_log\n",
    "data = {'covar':covar, 'x':x, 'y':y}; df = pd.DataFrame(data)\n",
    "stats = pg.partial_corr(data=df, x='x', y='y', covar='covar', method='spearman').round(3)\n",
    "r = stats['r'][0]\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "sample_size = power_analysis.solve_power(effect_size = r, alpha = 0.05, power = 0.95)\n",
    "print(sample_size/12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa203e0",
   "metadata": {},
   "source": [
    "#### 3. best/worst analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d07e409",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.37097285955292\n"
     ]
    }
   ],
   "source": [
    "from analysis_helpers import perf_by_type\n",
    "hum_low, hum_rnd, hum_upp, _ = perf_by_type(\n",
    "    post_amts_data_log, nsubjects, ntrials_persub, exp, list(range(nsubjects)), log=True)\n",
    "\n",
    "x = hum_low\n",
    "y = hum_upp\n",
    "\n",
    "u1 = np.mean(x); n1 = len(x); s1 = np.std(x)\n",
    "u2 = np.mean(y); n2 = len(y); s2 = np.std(y)\n",
    "d = (u1 - u2) / (np.sqrt( ((n1-1) * s1**2 + (n2-1) * s2**2 ) / (n1+n2-2)))\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "sample_size = power_analysis.solve_power(effect_size = d, alpha = 0.05, power = 0.95)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e881e",
   "metadata": {},
   "source": [
    "### <p></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
